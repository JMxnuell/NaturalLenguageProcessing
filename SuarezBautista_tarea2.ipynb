{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4426aa37",
   "metadata": {},
   "source": [
    "# ***Tratamiento del lenguaje Natural*** CIC - IPN\n",
    "\n",
    "### Suárez Bautista José Manuel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b0e3e6",
   "metadata": {},
   "source": [
    "En este ejercicio se utilizará el paquete *spacy* para ***tokenization*** y ***lemmatization***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c0a67",
   "metadata": {},
   "source": [
    "Primero importamos los paquetes necesarios. En este caso necesitaremos *spacy* para tokenization y lemmatization, de igual forma importaremos *pandas* para mostrar el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41c5174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c30d25",
   "metadata": {},
   "source": [
    "Posteriormente cargamos el pipeline que nos retornará el *Language object* necesario para procesar el texto deseado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba48257",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f4c45a",
   "metadata": {},
   "source": [
    "Despues de cargar el pipeline deseado procesamos el texto deseado llamando a nuestro objeto *nlp* con una cadena, devolviendonos un *doc nlp* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5d76320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ocupando sus lugares en el cohete, Neil Armstrong, Edwin Aldrin y\n",
      "Michael Collins compartían un vacío en el estómago. Esto era para lo que habían\n",
      "entrenado. Estaban listos. Pero la sombra del incendio del Apolo 1 acechaba en\n",
      "algún lugar remoto de sus mentes. Era inevitable.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Ocupando sus lugares en el cohete, Neil Armstrong, Edwin Aldrin y\n",
    "Michael Collins compartían un vacío en el estómago. Esto era para lo que habían\n",
    "entrenado. Estaban listos. Pero la sombra del incendio del Apolo 1 acechaba en\n",
    "algún lugar remoto de sus mentes. Era inevitable.\"\"\"\n",
    "print(text)\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbab31e",
   "metadata": {},
   "source": [
    "Finalmente presentamos en un dataframe la tokenization y lemmatization del texto procesado. Para esto crearemos un diccionario donde el token será una ***key*** y  la lemmatization el ***value*** y finalmente crearemos un dataframe con dicho diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca70891f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         token       lemma\n",
      "0     Ocupando      ocupar\n",
      "1          sus          su\n",
      "2      lugares       lugar\n",
      "3           en          en\n",
      "4           el          el\n",
      "5       cohete      cohete\n",
      "6            ,           ,\n",
      "7         Neil        Neil\n",
      "8    Armstrong   Armstrong\n",
      "9            ,           ,\n",
      "10       Edwin       Edwin\n",
      "11      Aldrin      Aldrin\n",
      "12           y           y\n",
      "13          \\n          \\n\n",
      "14     Michael     Michael\n",
      "15     Collins     Collins\n",
      "16  compartían   compartir\n",
      "17          un         uno\n",
      "18       vacío       vacío\n",
      "19          en          en\n",
      "20          el          el\n",
      "21    estómago    estómago\n",
      "22           .           .\n",
      "23        Esto        este\n",
      "24         era         ser\n",
      "25        para        para\n",
      "26          lo          él\n",
      "27         que         que\n",
      "28      habían       haber\n",
      "29          \\n          \\n\n",
      "30   entrenado    entrenar\n",
      "31           .           .\n",
      "32     Estaban       estar\n",
      "33      listos       listo\n",
      "34           .           .\n",
      "35        Pero        pero\n",
      "36          la          el\n",
      "37      sombra      sombra\n",
      "38         del         del\n",
      "39    incendio    incendio\n",
      "40         del         del\n",
      "41       Apolo       Apolo\n",
      "42           1           1\n",
      "43    acechaba     acechar\n",
      "44          en          en\n",
      "45          \\n          \\n\n",
      "46       algún      alguno\n",
      "47       lugar       lugar\n",
      "48      remoto      remoto\n",
      "49          de          de\n",
      "50         sus          su\n",
      "51      mentes       mente\n",
      "52           .           .\n",
      "53         Era         ser\n",
      "54  inevitable  inevitable\n",
      "55           .           .\n"
     ]
    }
   ],
   "source": [
    "tkns = [token.text for token in doc]\n",
    "lmms = [token.lemma_ for token in doc]\n",
    "dict = {'token': tkns, 'lemma':lmms}\n",
    "table = pd.DataFrame(dict)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae098e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
